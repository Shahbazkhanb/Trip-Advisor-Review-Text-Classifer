{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset & pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change to local path to data\n",
    "path = \"C://Users//User//Documents//Python Scripts//Data//tripadvisor_hotel_reviews.csv\"\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Dataset has 20,491 reviews\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning out punctuation & creating a new column to classify reviews as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4 experience hotel monaco seatt...</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay went seahawk game awesom...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Attitude\n",
       "0  nice hotel expensive parking got good deal sta...       4  Positive\n",
       "1  ok nothing special charge diamond member hilto...       2  Negative\n",
       "2  nice rooms not 4 experience hotel monaco seatt...       3  Positive\n",
       "3  unique great stay wonderful time hotel monaco ...       5  Positive\n",
       "4  great stay great stay went seahawk game awesom...       5  Positive"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Review\"] = data[\"Review\"].str.replace(r\"[^\\w\\s]+\", '')\n",
    "\n",
    "data[\"Attitude\"] = [\"Positive\" if i > 2 else \"Negative\" for i in data[\"Rating\"]]\n",
    "\n",
    "# 84% of comments are rated Positive while the remaining 16% are negative\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6763 , 13728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size = .33, random_state = 10, stratify = data[\"Attitude\"], shuffle = True)\n",
    "\n",
    "train = train.iloc[:,[0,2]]\n",
    "print(len(test), \",\", len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the review strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "trained_vec = vect.fit_transform(train[\"Review\"])\n",
    "\n",
    "test_vecs = vect.transform(test[\"Review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_ = svm.SVC(kernel = \"linear\")\n",
    "svm_.fit(trained_vec, train[\"Attitude\"])\n",
    "\n",
    "print(svm_.predict(test_vecs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Was the classification correct? It correctly guessed that the 4 star review below was indeed positve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review  Rating  Attitude\n",
      "11370  nicer read husband stayed water beach hotel su...       4  Positive\n"
     ]
    }
   ],
   "source": [
    "print(test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_ = LogisticRegression(solver='lbfgs', max_iter = 2000)\n",
    "log_.fit(trained_vec, train[\"Attitude\"])\n",
    "\n",
    "print(log_.predict(test_vecs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multi_ = MultinomialNB()\n",
    "multi_.fit(trained_vec, train[\"Attitude\"])\n",
    "\n",
    "print(multi_.predict(test_vecs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_ = DecisionTreeClassifier()\n",
    "dec_.fit(trained_vec, train[\"Attitude\"])\n",
    "\n",
    "print(dec_.predict(test_vecs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to Compare Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9129\n",
      "0.9203\n",
      "0.9196\n",
      "0.8622\n"
     ]
    }
   ],
   "source": [
    "svm_mean_score_1 = round(svm_.score(test_vecs, test[\"Attitude\"]), 4)\n",
    "log_mean_score_1 = round(log_.score(test_vecs, test[\"Attitude\"]), 4)\n",
    "multi_mean_score_1 = round(multi_.score(test_vecs, test[\"Attitude\"]), 4)\n",
    "dec_mean_score_1 = round(dec_.score(test_vecs, test[\"Attitude\"]), 4)\n",
    "\n",
    "\n",
    "print(svm_mean_score_1)\n",
    "print(log_mean_score_1)\n",
    "print(multi_mean_score_1)\n",
    "print(dec_mean_score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9485 0.7172]\n",
      "[0.9532 0.7328]\n",
      "[0.9537 0.6937]\n",
      "[0.9191 0.5345]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from numpy import around as around\n",
    "\n",
    "\n",
    "f1_svm_1 = around(f1_score(test[\"Attitude\"], svm_.predict(test_vecs), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)\n",
    "f1_log_1 = around(f1_score(test[\"Attitude\"], log_.predict(test_vecs), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)\n",
    "f1_multi_1 = around(f1_score(test[\"Attitude\"], multi_.predict(test_vecs), average = None, \n",
    "                             labels = [\"Positive\", \"Negative\"]), 4)\n",
    "f1_dec_1 = around(f1_score(test[\"Attitude\"], dec_.predict(test_vecs), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)\n",
    "\n",
    "\n",
    "print(f1_svm_1)\n",
    "print(f1_log_1)\n",
    "print(f1_multi_1)\n",
    "print(f1_dec_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that Multinomial Naive Bayes SVM and Logistic Regression  has the highest mean and F1 scores! Lets see how these models performs on some test data we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative' 'Positive' 'Negative' 'Positive' 'Positive']\n",
      "['Negative' 'Positive' 'Negative' 'Positive' 'Positive']\n",
      "['Negative' 'Positive' 'Negative' 'Positive' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "fake_test = [\"Worst ever\", \"love it\", \"terrible\", 'Great service', 'hate this place']\n",
    "round2 = vect.transform(fake_test)\n",
    "\n",
    "print(svm_.predict(round2))\n",
    "print(log_.predict(round2))\n",
    "print(multi_.predict(round2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does the modeld think the last example is positive? Upon further inspection of the dataset, the word \"hate\" was not used exclusively as a negative. instead many positive reviews used the word. This and other oddities can be corrected with a larger training data set. The discrepency can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive' 'Positive' 'Positive' 'Positive']\n",
      "['Positive' 'Positive' 'Positive' 'Positive']\n",
      "['Positive' 'Negative' 'Positive' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "fake_test2 = [\"I HATE THIS\", \"HATE LIVING HERE\", \"HATED THIS PLACE\", 'HATED THE SERVICE']\n",
    "round3 = vect.transform(fake_test2)\n",
    "\n",
    "print(svm_.predict(round3))\n",
    "print(log_.predict(round3))\n",
    "print(multi_.predict(round3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFID Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The earlier count vectorizer gives equal weight to all words appearing in a review. Therefore prepositions, articles, nouns and other non-descriptive words are given a much higher weight in determining the \"attitude\" of a review just because they occur more frequently in speech. For example, in the below, the words \"I\", \"this\" and \"place\" are given the same weight in the model as the words \"love\" and \"hate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'I hate this place'\n",
    "# 'I love this place'\n",
    "\n",
    "# The words that actually matter ('love' & 'hate') should be given more weight than all the other words. \n",
    "# Therefore using a TFID vectorizer will correct this as instead of giving more weight to words that \n",
    "# occur more frequently, it will assign greater weight to words that occur more RARELY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9574 0.7454]\n",
      "[0.9538 0.6965]\n",
      "[0.9149 0.    ]\n",
      "[0.9075 0.4938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Re-vectorizing with TFID\n",
    "vect2 = TfidfVectorizer()\n",
    "trained_vec2 = vect2.fit_transform(train[\"Review\"])\n",
    "\n",
    "test_vecs2 = vect2.transform(test[\"Review\"])\n",
    "\n",
    "# Re-modelling with new vectorizor\n",
    "svm_2 = svm.SVC(kernel = \"linear\")\n",
    "svm_2.fit(trained_vec2, train[\"Attitude\"])\n",
    "\n",
    "log_2 = LogisticRegression(solver='lbfgs')\n",
    "log_2.fit(trained_vec2, train[\"Attitude\"])\n",
    "\n",
    "multi_2 = MultinomialNB()\n",
    "multi_2.fit(trained_vec2, train[\"Attitude\"])\n",
    "\n",
    "dec_2 = DecisionTreeClassifier()\n",
    "dec_2.fit(trained_vec2, train[\"Attitude\"])\n",
    "\n",
    "# New F1 Scores\n",
    "f1_svm_2 = around(f1_score(test[\"Attitude\"], svm_2.predict(test_vecs2), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)\n",
    "f1_log_2 = around(f1_score(test[\"Attitude\"], log_2.predict(test_vecs2), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)\n",
    "f1_multi_2 = around(f1_score(test[\"Attitude\"], multi_2.predict(test_vecs2), average = None, \n",
    "                             labels = [\"Positive\", \"Negative\"]), 4)\n",
    "f1_dec_2 = around(f1_score(test[\"Attitude\"], dec_2.predict(test_vecs2), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)\n",
    "\n",
    "print(f1_svm_2)\n",
    "print(f1_log_2)\n",
    "print(f1_multi_2)\n",
    "print(f1_dec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927\n",
      "0.9199\n",
      "0.8431\n",
      "0.8436\n"
     ]
    }
   ],
   "source": [
    "# New mean performance scores\n",
    "svm_mean_score_2 = round(svm_2.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "log_mean_score_2 = round(log_2.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "multi_mean_score_2 = round(multi_2.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "dec_mean_score_2 = round(dec_2.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "\n",
    "print(svm_mean_score_2)\n",
    "print(log_mean_score_2)\n",
    "print(multi_mean_score_2)\n",
    "print(dec_mean_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm performance difference from basic vectorizing to TFID:\n",
      "mean score  0.0141 \n",
      "f1 scores:  [0.0089 0.0282] \n",
      "\n",
      "logistic performance difference from basic vectorizing to TFID:\n",
      "mean score  -0.0004 \n",
      "f1 scores:  [ 0.0006 -0.0363] \n",
      "\n",
      "multi NB performance difference from basic vectorizing to TFID:\n",
      "mean score  -0.0765 \n",
      "f1 scores:  [-0.0388 -0.6937] \n",
      "\n",
      "decision tree NB performance difference from basic vectorizing to TFID:\n",
      "mean score  -0.0186 \n",
      "f1 scores:  [-0.0116 -0.0407]\n"
     ]
    }
   ],
   "source": [
    "print(\"svm performance difference from basic vectorizing to TFID:\\nmean score \"\n",
    "      , round((svm_mean_score_2 - svm_mean_score_1), 4),\"\\nf1 scores: \", around((f1_svm_2 - f1_svm_1), 4), \"\\n\")\n",
    "print(\"logistic performance difference from basic vectorizing to TFID:\\nmean score \"\n",
    "      , round((log_mean_score_2 - log_mean_score_1), 4),\"\\nf1 scores: \", around((f1_log_2 - f1_log_1), 4), \"\\n\")\n",
    "print(\"multi NB performance difference from basic vectorizing to TFID:\\nmean score \"\n",
    "      , round((multi_mean_score_2 - multi_mean_score_1), 4),\"\\nf1 scores: \", around((f1_multi_2 - f1_multi_1), 4), \"\\n\")\n",
    "print(\"decision tree NB performance difference from basic vectorizing to TFID:\\nmean score \"\n",
    "      , round((dec_mean_score_2 - dec_mean_score_1), 4),\"\\nf1 scores: \", around((f1_dec_2 - f1_dec_1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramater Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it seems that the increase in accuracy was nominal for the SVM model, lowered slightly for the logistic regression and vastly degraded for the Multinomial Bayes. Lets try parameter tuning using GridSearch to see if we can get a more substantial increase! (We will drop the decision tree model as it is seeing poorer results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first for SVM (this takes a very long time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': (1, 2, 4), 'gamma': ['scale'],\n",
       "                         'kernel': ('linear', 'poly', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "test_params = {\"C\": (1, 2, 4), \"kernel\": (\"linear\", \"poly\", \"rbf\"), \"gamma\": [\"scale\"]}\n",
    "\n",
    "svc_3 = svm.SVC()\n",
    "svc_clf = GridSearchCV(svc_3, test_params, cv = 3)\n",
    "\n",
    "svc_clf.fit(trained_vec2, train[\"Attitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mean_score_3 = round(svc_clf.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "f1_svm_3 = around(f1_score(test[\"Attitude\"], svc_clf.predict(test_vecs2), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params_log = {\"solver\":(\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\")}\n",
    "\n",
    "log_3 = LogisticRegression(solver='lbfgs')\n",
    "log_clf = GridSearchCV(log_3, test_params_log, cv = 3)\n",
    "\n",
    "log_clf.fit(trained_vec2, train[\"Attitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mean_score_3 = round(log_clf.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "f1_log_3 = around(f1_score(test[\"Attitude\"], log_clf.predict(test_vecs2), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='warn', n_jobs=None, param_grid={'alpha': (0.5, 1.0, 2.0)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params_multi = {\"alpha\": (0.5, 1.0, 2.0)}\n",
    "\n",
    "multi3 = MultinomialNB()\n",
    "multi_clf = GridSearchCV(multi3, test_params_multi, cv = 3)\n",
    "\n",
    "multi_clf.fit(trained_vec2, train[\"Attitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_mean_score_3 = round(multi_clf.score(test_vecs2, test[\"Attitude\"]), 4)\n",
    "f1_multi_3 = around(f1_score(test[\"Attitude\"], multi_clf.predict(test_vecs2), average = None, \n",
    "                           labels = [\"Positive\", \"Negative\"]), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see below there has been very little model improvement after parameter tuning. Only the multinomial naive bayes had any change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm performance difference from base TFID models to paramater tuned models:\n",
      "mean score  0.0 \n",
      "f1 scores:  [0. 0.] \n",
      "\n",
      "logistic performance difference from base TFID models to paramater tuned models:\n",
      "mean score  0.0 \n",
      "f1 scores:  [0. 0.] \n",
      "\n",
      "multi performance difference from base TFID models to paramater tuned models:\n",
      "mean score  0.0011 \n",
      "f1 scores:  [0.0005 0.0131] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"svm performance difference from base TFID models to paramater tuned models:\\nmean score \"\n",
    "      , round((svm_mean_score_3 - svm_mean_score_2), 4),\"\\nf1 scores: \", around((f1_svm_3 - f1_svm_2), 4), \"\\n\")\n",
    "print(\"logistic performance difference from base TFID models to paramater tuned models:\\nmean score \"\n",
    "      , round((log_mean_score_3 - log_mean_score_2), 4),\"\\nf1 scores: \", around((f1_log_3 - f1_log_2), 4), \"\\n\")\n",
    "print(\"multi performance difference from base TFID models to paramater tuned models:\\nmean score \"\n",
    "      , round((multi_mean_score_3 - multi_mean_score_2), 4),\"\\nf1 scores: \", around((f1_multi_3 - f1_multi_2), 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the SVM model below has produced the most accurate model and so is our final selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final svm performance for TFID models post paramater tuning:\n",
      "mean score  0.927 \n",
      "f1 scores:  [0.9574 0.7454] \n",
      "\n",
      "final logistic performance for TFID models post paramater tuning:\n",
      "mean score  0.9199 \n",
      "f1 scores:  [0.9538 0.6965] \n",
      "\n",
      "final multinomial naive bayesp performance for TFID models post paramater tuning:\n",
      "mean score  0.8442 \n",
      "f1 scores:  [0.9154 0.0131] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"final svm performance for TFID models post paramater tuning:\\nmean score \"\n",
    "      , round((svm_mean_score_3), 4),\"\\nf1 scores: \", around((f1_svm_3), 4), \"\\n\")\n",
    "print(\"final logistic performance for TFID models post paramater tuning:\\nmean score \"\n",
    "      , round((log_mean_score_3), 4),\"\\nf1 scores: \", around((f1_log_3), 4), \"\\n\")\n",
    "print(\"final multinomial naive bayesp performance for TFID models post paramater tuning:\\nmean score \"\n",
    "      , round((multi_mean_score_3), 4),\"\\nf1 scores: \", around((f1_multi_3), 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Change to local path to desired folder\n",
    "with open('C://Users//User//Documents//Python Scripts//Data//SVM_review_classifer.pkl', 'wb') as file:\n",
    "    pickle.dump(svc_clf, file)\n",
    "    \n",
    "with open('C://Users//User//Documents//Python Scripts//Data//SVM_review_classifer.pkl', 'rb') as file2:\n",
    "    load_svm = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nicer read husband stayed water beach hotel sunday june 15 thursday june 19th 6th wedding anniversary sunday thursday key stay week no weekends want experience nice hotel noise rooftop bar guest complained really enjoyed rooms little cramped nice clean staff nice pleasant door man beach valet nice men extremely helpfulthe nicest experience hotel rooftop pool lounge area perfect romantic way relax able enjoy drinks food hotel pretty costly thing somewhat unpleased  \n",
      "\n",
      "Review gave score of  4 \n",
      "\n",
      "prediction is: Positive\n"
     ]
    }
   ],
   "source": [
    "print(test.iloc[0,0])\n",
    "print(\"\\nReview gave score of \", test.iloc[0,1],\"\\n\")\n",
    "print(\"prediction is:\", load_svm.predict(test_vecs2[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Confusion Matrix to show accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preds = load_svm.predict(test_vecs2)\n",
    "\n",
    "labels = [\"Positive\", \"Negative\"]\n",
    "matrix = confusion_matrix(test[\"Attitude\"], preds, labels = labels)\n",
    "matrix_df = pd.DataFrame(matrix, index = labels, columns = labels)\n",
    "\n",
    "sn.heatmap(matrix_df, annot = True, fmt = \"d\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get better accuracy, need a dataset with more negative reviews to test the data on. Here, negative reviews accounted for only 16% of the dataset causing our models to skew towards predicting \"Positive\" outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
